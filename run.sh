#!/bin/bash
# AI ììœ¨ ë°©ì†¡ ì‹œìŠ¤í…œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# Ollama ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ â†’ ê°€ìƒí™˜ê²½ í™œì„±í™” â†’ ì‹œìŠ¤í…œ ì‹¤í–‰

set -e

# Ollama ì²´í¬
if ! command -v ollama &> /dev/null; then
    echo "âŒ Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    echo "ì„¤ì¹˜: curl -fsSL https://ollama.com/install.sh | sh"
    exit 1
fi

# Ollama ì„œë¹„ìŠ¤ ì‹¤í–‰ í™•ì¸
if ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "ğŸ”„ Ollama ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
    ollama serve &
    sleep 3
fi

# ëª¨ë¸ ì²´í¬ ë° ìë™ ë‹¤ìš´ë¡œë“œ
MODEL=$(python3 -c "import yaml; print(yaml.safe_load(open('config/settings.yaml'))['llm']['model'])" 2>/dev/null || echo "llama3")
if ! ollama list | grep -q "$MODEL"; then
    echo "ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘: $MODEL"
    ollama pull "$MODEL"
fi

# ê°€ìƒí™˜ê²½ í™œì„±í™”
if [ -d "venv" ]; then
    source venv/bin/activate
fi

# ì‹¤í–‰
python src/main.py "$@"
